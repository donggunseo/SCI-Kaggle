{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install autocorrect -qq \n",
    "! pip install glove_python_binary | grep satistfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/scijspirit/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../input/feedback-prize-2021/\"\n",
    "TRAIN_DIR = BASE_DIR + 'train'\n",
    "SAVE_DIR = BASE_DIR + 'train_oversamples'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.mkdir(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>8</td>\n",
       "      <td>229</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>230</td>\n",
       "      <td>312</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>313</td>\n",
       "      <td>400</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>402</td>\n",
       "      <td>757</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>759</td>\n",
       "      <td>886</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id discourse_type discourse_type_num  \\\n",
       "0  423A1CA112E2  1.622628e+12           Lead             Lead 1   \n",
       "1  423A1CA112E2  1.622628e+12       Position         Position 1   \n",
       "2  423A1CA112E2  1.622628e+12       Evidence         Evidence 1   \n",
       "3  423A1CA112E2  1.622628e+12       Evidence         Evidence 2   \n",
       "4  423A1CA112E2  1.622628e+12          Claim            Claim 1   \n",
       "\n",
       "   discourse_start  discourse_end  \\\n",
       "0                8            229   \n",
       "1              230            312   \n",
       "2              313            400   \n",
       "3              402            757   \n",
       "4              759            886   \n",
       "\n",
       "                                      discourse_text  \\\n",
       "0  Modern humans today are always on their phone....   \n",
       "1  They are some really bad consequences when stu...   \n",
       "2  Some certain areas in the United States ban ph...   \n",
       "3  When people have phones, they know about certa...   \n",
       "4  Driving is one of the way how to get around. P...   \n",
       "\n",
       "                                    predictionstring  \n",
       "0  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISCOURSE_TYPES = ['Rebuttal', 'Counterclaim', 'Lead', 'Concluding Statement', 'Claim', 'Position', 'Evidence']\n",
    "WEAK_DISCOURSE_TYPES = ['Rebuttal', 'Counterclaim']\n",
    "FULL_DISCOURSE_TYPES = ['Lead', 'Concluding Statement', 'Claim', 'Position', 'Evidence']\n",
    "\n",
    "\n",
    "df = pd.read_csv(BASE_DIR + \"train_corrected.csv\")      \n",
    "\n",
    "df.drop(['discourse_start', 'discourse_end', 'discourse_text', 'predictionstring'], axis='columns', inplace=True)\n",
    "df.rename(columns = {'new_start':'discourse_start', 'new_end':'discourse_end', 'new_discourse_text':'discourse_text', 'new_predictionstring':'predictionstring'}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [00:00<00:00, 112407.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B7E936A82959</td>\n",
       "      <td>The advantages of limiting car usages is that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7D59699BB70F</td>\n",
       "      <td>One of the advantages of getting rid of cars i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6163745AA739</td>\n",
       "      <td>Have you ever been driving a car and wish that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6770F94889E2</td>\n",
       "      <td>Ever thought of a car that drives itself? Seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F8173F146C1B</td>\n",
       "      <td>I've never had to complete a summer project be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  B7E936A82959  The advantages of limiting car usages is that ...\n",
       "1  7D59699BB70F  One of the advantages of getting rid of cars i...\n",
       "2  6163745AA739  Have you ever been driving a car and wish that...\n",
       "3  6770F94889E2  Ever thought of a car that drives itself? Seem...\n",
       "4  F8173F146C1B  I've never had to complete a summer project be..."
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def open_txt():\n",
    "    train_names, train_texts = [], []\n",
    "    for f in tqdm(list(os.listdir(TRAIN_DIR))):\n",
    "        train_names.append(f.replace('.txt', ''))\n",
    "        train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r', encoding='utf-8').read())\n",
    "    train_text_df = pd.DataFrame({'id': train_names, 'text': train_texts})\n",
    "\n",
    "    return train_text_df\n",
    "\n",
    "train_text_df = open_txt()\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rebuttal                 3598\n",
       "Counterclaim             4576\n",
       "Lead                     9301\n",
       "Concluding Statement    13418\n",
       "Claim                   14927\n",
       "Position                15366\n",
       "Evidence                15550\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ids = list(df['id'].unique())\n",
    "id2types = df.groupby('id')['discourse_type'].unique().to_dict()\n",
    "\n",
    "def train_ids2discourse_type_counts(X_ids):\n",
    "    \n",
    "    no_num = re.compile('[^0-9]')\n",
    "    type_count = dict([(dt, 0) for dt  in DISCOURSE_TYPES])\n",
    "    \n",
    "    for _id in X_ids:\n",
    "        for dt in id2types[_id]:\n",
    "            dt_name = \"\".join(no_num.findall(dt)).rstrip(\" \")\n",
    "            type_count[dt_name] += 1\n",
    "            \n",
    "    return pd.Series(type_count).sort_values()\n",
    "\n",
    "type_count = train_ids2discourse_type_counts(X_ids)\n",
    "type_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuttal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:37<00:00, 18.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FILL_TO = max(type_count)\n",
    "add_ids = []\n",
    "# Oversample to Maximum Sample Count\n",
    "for dt in tqdm(WEAK_DISCOURSE_TYPES):\n",
    "    print(dt)\n",
    "    # Get current Discourse Type Count\n",
    "    type_count = train_ids2discourse_type_counts(X_ids)\n",
    "    dt_sample_count = type_count[dt]\n",
    "    if dt_sample_count < FILL_TO:\n",
    "        while dt_sample_count < FILL_TO:\n",
    "            # Take Random ID\n",
    "            random_id = str(np.random.choice(X_ids, 1).squeeze())\n",
    "            if dt in id2types[random_id] :\n",
    "                X_ids.append(random_id)\n",
    "                add_ids.append(random_id)\n",
    "                dt_sample_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling id count : 11952\n",
      "MAX count : 15550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rebuttal                15550\n",
       "Counterclaim            16521\n",
       "Lead                    17580\n",
       "Concluding Statement    24310\n",
       "Claim                   26560\n",
       "Position                27299\n",
       "Evidence                27475\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sampling id count :\", len(add_ids))\n",
    "print(\"MAX count :\", FILL_TO)\n",
    "train_ids2discourse_type_counts(X_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_misspelling(train_text):\n",
    "    correct_count = 0\n",
    "    spell = Speller(lang='en')\n",
    "    for idx, word in enumerate(train_text):\n",
    "        cor_word = spell(word)\n",
    "        if word != cor_word:\n",
    "            train_text[idx] = cor_word\n",
    "            correct_count += 1\n",
    "    return train_text, correct_count\n",
    "\n",
    "# txt = 'mismatch! so cannot oversampling this discorse tpye'\n",
    "# train_text = txt.split()\n",
    "# correct_misspelling(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:02<00:00, 187511.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 words loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GLOVE_PATH = '../glove/glove_6B/glove.6B.50d.txt'\n",
    "with open(GLOVE_PATH, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "glove_model = {}\n",
    "for line in tqdm(lines):\n",
    "    split_line = line.split()\n",
    "    word = split_line[0]\n",
    "    embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "    glove_model[word] = embedding\n",
    "print(f\"{len(glove_model)} words loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "    a = glove_model[word]\n",
    "    best = (None, 0.0)\n",
    "    for w, b in glove_model.items():\n",
    "        value = dot(a, b)/(norm(a)*norm(b))\n",
    "        if w != word and value > best[1]:\n",
    "            best = (w, value)\n",
    "    return best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_change(example, txt):\n",
    "    PUNCTUATION = set([\".\",\",\",\";\"])\n",
    "    ALLOW_POS_TAGS = ['JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNPS', 'RBR', 'RBS', 'VB', 'VBD', 'VBG']\n",
    "    \n",
    "    discourse_text = example['discourse_text'].split()\n",
    "    predictionstring = example['predictionstring'].split()\n",
    "    # train_text = example['text'].split()\n",
    "    train_text = txt.split()\n",
    "    \n",
    "    if len(discourse_text) != len(predictionstring):\n",
    "        print(\"mismatch! so cannot oversampling this discorse type\")\n",
    "        return \n",
    "    \n",
    "    # correct misspelling\n",
    "    train_text, correction_count = correct_misspelling(train_text)\n",
    "    \n",
    "    # synonym replacement\n",
    "    \n",
    "    is_replaced = False\n",
    "    while not is_replaced:\n",
    "        list_idx = int(np.random.choice(len(predictionstring), 1))\n",
    "        txt_idx = int(predictionstring[list_idx])\n",
    "        origin_word = discourse_text[list_idx]\n",
    "        \n",
    "        pos_tag = nltk.pos_tag([origin_word])[0][1]\n",
    "        if PUNCTUATION & set(list(origin_word)) or (origin_word not in glove_model.keys()) or (pos_tag not in ALLOW_POS_TAGS):\n",
    "            continue\n",
    "        \n",
    "        replace_word = most_similar(origin_word)\n",
    "        \n",
    "        train_text[txt_idx] = replace_word\n",
    "        discourse_text[list_idx] = replace_word\n",
    "        is_replaced = True\n",
    "            \n",
    "    example['predictionstring'] = example['predictionstring']\n",
    "    example['discourse_text'] = \" \".join(discourse_text)\n",
    "    txt = \" \".join(train_text)\n",
    "    \n",
    "    return example, txt, correction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversamplig(df):\n",
    "    new_df = pd.DataFrame(columns=df.columns)\n",
    "    for id in tqdm(add_ids):\n",
    "        count = 0\n",
    "        new_id = \"{0}_S\".format(id)\n",
    "        \n",
    "        examples = df[df.id == id]          # id의 모든 discourse type 행을 추출\n",
    "        text = train_text_df[train_text_df.id == id]['text'].values[0]  # id에 맞는 원본 text를 로드\n",
    "        \n",
    "        for i, example in examples.iterrows(): \n",
    "            # id내 annotation된 discourse type을 살피면서 워드를 바꾼다.\n",
    "            # Rebuttal, Counterclaim인 경우, 무조건 바꿈\n",
    "            # 그외 타입인 경우, 확률적으로 바꿈.\n",
    "            #\n",
    "            # discourse type이 변경된 경우, df에 계속해서 추가한다.\n",
    "            # text는 모든 변경사항을 누적시키며, for문이 끝난 후 새로운 파일로 저장함.\n",
    "            new_example = example.copy()\n",
    "            if example['discourse_type'] in WEAK_DISCOURSE_TYPES:\n",
    "                new_example, text, correction_count = do_change(new_example, text)\n",
    "                count += 1\n",
    "                ## for debug\n",
    "                # print(example['discourse_type_num'])\n",
    "                # print(example['discourse_text'])\n",
    "                # print(new_example['discourse_text'])\n",
    "                # print(train_text_df[train_text_df.id == id].text.values[0])\n",
    "                # print(text)\n",
    "            else:\n",
    "                if random.random() > 0.8:\n",
    "                    new_example, text, correction_count = do_change(new_example, text)\n",
    "                    count += 1\n",
    "                    ## for debug\n",
    "                    # print(example['discourse_type_num'])\n",
    "                    # print(example['discourse_text'])\n",
    "                    # print(new_example['discourse_text'])\n",
    "                    # print(train_text_df[train_text_df.id == id].text.values[0])\n",
    "                    # print(text)\n",
    "                \n",
    "            new_example['id'] = new_id\n",
    "            new_df = new_df.append(new_example)\n",
    "            \n",
    "        # save txt \n",
    "        with open(SAVE_DIR+ '/{0}.txt'.format(new_id), 'w') as f:\n",
    "            f.write(text)\n",
    "            \n",
    "        print(\"new_id: {0} \\t Add {2} discourse types. (# of synonym raplacement: {3}, # of correction misspelling: {4}\".format(new_id, len(new_df), len(examples), count, correction_count))     \n",
    "    print(\"complete oversampling --  total new rows : \", len(new_df))         \n",
    "    return new_df\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "print(len(new_df))\n",
    "new_df = oversamplig(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('train_oversampled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5aa82812c4681f8310f3f49363d12ac4c7be23abd4617d81f239e4ef56509db9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
