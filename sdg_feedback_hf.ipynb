{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "train = pd.read_csv('../input/feedback-prize-2021/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead',\n",
       " 'Position',\n",
       " 'Evidence',\n",
       " 'Claim',\n",
       " 'Concluding Statement',\n",
       " 'Counterclaim',\n",
       " 'Rebuttal']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = train.discourse_type.unique().tolist()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "tags = defaultdict()\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    tags[f'B-{c}'] = i\n",
    "    tags[f'I-{c}'] = i + len(classes)\n",
    "tags[f'O'] = len(classes) * 2\n",
    "tags[f'Special'] = -100\n",
    "    \n",
    "l2i = dict(tags)\n",
    "\n",
    "i2l = defaultdict()\n",
    "for k, v in l2i.items(): \n",
    "    i2l[v] = k\n",
    "i2l[-100] = 'Special'\n",
    "\n",
    "i2l = dict(i2l)\n",
    "\n",
    "N_LABELS = len(i2l) - 1 # not accounting for -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-Lead': 0,\n",
       " 'I-Lead': 7,\n",
       " 'B-Position': 1,\n",
       " 'I-Position': 8,\n",
       " 'B-Evidence': 2,\n",
       " 'I-Evidence': 9,\n",
       " 'B-Claim': 3,\n",
       " 'I-Claim': 10,\n",
       " 'B-Concluding Statement': 4,\n",
       " 'I-Concluding Statement': 11,\n",
       " 'B-Counterclaim': 5,\n",
       " 'I-Counterclaim': 12,\n",
       " 'B-Rebuttal': 6,\n",
       " 'I-Rebuttal': 13,\n",
       " 'O': 14,\n",
       " 'Special': -100}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [00:00<00:00, 27307.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4BCA0580352F</td>\n",
       "      <td>Isn't it wonderful to know that you get a chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29A8E6DA6F04</td>\n",
       "      <td>One uses a car to go to the store, pick someon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17E8BB6C550B</td>\n",
       "      <td>Driverless cars do seem like the thing today's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319B2511943D</td>\n",
       "      <td>Have you ever thought your choice wasn't the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C9B1827498E4</td>\n",
       "      <td>Imagine you're sitting at home, watching a sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  4BCA0580352F  Isn't it wonderful to know that you get a chan...\n",
       "1  29A8E6DA6F04  One uses a car to go to the store, pick someon...\n",
       "2  17E8BB6C550B  Driverless cars do seem like the thing today's...\n",
       "3  319B2511943D  Have you ever thought your choice wasn't the b...\n",
       "4  C9B1827498E4  Imagine you're sitting at home, watching a sho..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_names, train_texts = [], []\n",
    "for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r', encoding='utf-8').read())\n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , 10000 , 10100 , 10200 , 10300 , 10400 , 10500 , 10600 , 10700 , 10800 , 10900 , 11000 , 11100 , 11200 , 11300 , 11400 , 11500 , 11600 , 11700 , 11800 , 11900 , 12000 , 12100 , 12200 , 12300 , 12400 , 12500 , 12600 , 12700 , 12800 , 12900 , 13000 , 13100 , 13200 , 13300 , 13400 , 13500 , 13600 , 13700 , 13800 , 13900 , 14000 , 14100 , 14200 , 14300 , 14400 , 14500 , 14600 , 14700 , 14800 , 14900 , 15000 , 15100 , 15200 , 15300 , 15400 , 15500 , "
     ]
    }
   ],
   "source": [
    "all_entities = []\n",
    "all_text_list = []\n",
    "for ii,i in enumerate(train_text_df.iterrows()):\n",
    "    if ii%100==0: print(ii,', ',end='')\n",
    "    total = i[1]['text'].split().__len__()\n",
    "    text_list = i[1]['text'].split()\n",
    "    entities = [\"O\"]*total\n",
    "    for j in train[train['id'] == i[1]['id']].iterrows():\n",
    "        discourse = j[1]['discourse_type']\n",
    "        list_ix = [int(x) for x in j[1]['predictionstring'].split(' ')]\n",
    "        entities[list_ix[0]] = f\"B-{discourse}\"\n",
    "        for k in list_ix[1:]: entities[k] = f\"I-{discourse}\"\n",
    "    all_entities.append(entities)\n",
    "    all_text_list.append(text_list)\n",
    "train_text_df['entities'] = all_entities\n",
    "train_text_df['text_list'] = all_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15594, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>text_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4BCA0580352F</td>\n",
       "      <td>Isn't it wonderful to know that you get a chan...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>[Isn't, it, wonderful, to, know, that, you, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29A8E6DA6F04</td>\n",
       "      <td>One uses a car to go to the store, pick someon...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>[One, uses, a, car, to, go, to, the, store,, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17E8BB6C550B</td>\n",
       "      <td>Driverless cars do seem like the thing today's...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>[Driverless, cars, do, seem, like, the, thing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319B2511943D</td>\n",
       "      <td>Have you ever thought your choice wasn't the b...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>[Have, you, ever, thought, your, choice, wasn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C9B1827498E4</td>\n",
       "      <td>Imagine you're sitting at home, watching a sho...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>[Imagine, you're, sitting, at, home,, watching...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  4BCA0580352F  Isn't it wonderful to know that you get a chan...   \n",
       "1  29A8E6DA6F04  One uses a car to go to the store, pick someon...   \n",
       "2  17E8BB6C550B  Driverless cars do seem like the thing today's...   \n",
       "3  319B2511943D  Have you ever thought your choice wasn't the b...   \n",
       "4  C9B1827498E4  Imagine you're sitting at home, watching a sho...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...   \n",
       "1  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...   \n",
       "2  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...   \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...   \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...   \n",
       "\n",
       "                                           text_list  \n",
       "0  [Isn't, it, wonderful, to, know, that, you, ge...  \n",
       "1  [One, uses, a, car, to, go, to, the, store,, p...  \n",
       "2  [Driverless, cars, do, seem, like, the, thing,...  \n",
       "3  [Have, you, ever, thought, your, choice, wasn'...  \n",
       "4  [Imagine, you're, sitting, at, home,, watching...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( train_text_df.shape)\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'text_list'],\n",
       "        num_rows: 14034\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'text_list'],\n",
       "        num_rows: 1560\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_pandas(train_text_df)\n",
    "datasets = ds.train_test_split(test_size = 0.1, shuffle=True, seed=42)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_beginnings(labels):\n",
    "    for i in range(1,len(labels)):\n",
    "        curr_lab = labels[i]\n",
    "        prev_lab = labels[i-1]\n",
    "        if curr_lab in range(7,14):\n",
    "            if prev_lab != curr_lab and prev_lab != curr_lab - 7:\n",
    "                labels[i] = curr_lab -7\n",
    "    return labels\n",
    "\n",
    "def preparing_train_dataset(examples):\n",
    "    encoding = tokenizer(examples['text_list'], truncation=True, padding=True, max_length = 1024, is_split_into_words=True)\n",
    "    total= len(encoding['input_ids'])\n",
    "    encoding['word_ids']=[]\n",
    "    encoding['labels']=[]\n",
    "    for i in range(total):\n",
    "        labels = [l2i['O'] for _ in range(len(encoding['input_ids'][i]))]\n",
    "        word_idx = encoding.word_ids(batch_index=i)\n",
    "        for j in range(len(word_idx)):\n",
    "            if word_idx[j] is None:\n",
    "                labels[j]=l2i['Special']\n",
    "            else:\n",
    "                label = examples['entities'][i][word_idx[j]]\n",
    "                labels[j]=l2i[label]\n",
    "        labels = fix_beginnings(labels)\n",
    "        encoding['labels'].append(labels)\n",
    "        encoding['word_ids'].append(word_idx)\n",
    "        \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05747c7f3bb148389c9b931a42d928c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12bb498e1af442f958e47c7d4146955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(preparing_train_dataset, batched=True, batch_size=10000, remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForTokenClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained('allenai/longformer-base-4096')\n",
    "config.num_labels = N_LABELS\n",
    "model = AutoModelForTokenClassification.from_pretrained('allenai/longformer-base-4096', config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = './output/longformer-baseline',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    gradient_accumulation_steps = 2,\n",
    "    learning_rate = 5e-5,\n",
    "    weight_decay = 0.01,\n",
    "    max_grad_norm = 10,\n",
    "    num_train_epochs = 10,\n",
    "    warmup_ratio = 0.1,\n",
    "    logging_strategy = 'steps',\n",
    "    logging_steps = 50,\n",
    "    save_strategy = 'epoch',\n",
    "    save_total_limit = 1,\n",
    "    seed = 42,\n",
    "    # eval_steps = 50,\n",
    "    # save_steps = 50,\n",
    "    dataloader_num_workers = 2,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'f1',# need to fix\n",
    "    group_by_length = True,\n",
    "    report_to = 'wandb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric('seqeval')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    true_predictions = [\n",
    "        [i2l[p] for (p, l) in zip(prediction, label) if l!= -100] for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [i2l[l] for (p, l) in zip(prediction, label) if l!= -100] for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mquarter100\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/donggunseo/Feedback-prize/runs/3o147wzi\" target=\"_blank\">longformer-baseline</a></strong> to <a href=\"https://wandb.ai/donggunseo/Feedback-prize\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14034\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 8770\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8770' max='8770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8770/8770 5:20:15, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.705900</td>\n",
       "      <td>0.654413</td>\n",
       "      <td>0.136531</td>\n",
       "      <td>0.266782</td>\n",
       "      <td>0.180624</td>\n",
       "      <td>0.783154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.596400</td>\n",
       "      <td>0.593971</td>\n",
       "      <td>0.228696</td>\n",
       "      <td>0.373329</td>\n",
       "      <td>0.283639</td>\n",
       "      <td>0.799208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>0.590403</td>\n",
       "      <td>0.251668</td>\n",
       "      <td>0.420714</td>\n",
       "      <td>0.314941</td>\n",
       "      <td>0.800573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.606960</td>\n",
       "      <td>0.261331</td>\n",
       "      <td>0.432975</td>\n",
       "      <td>0.325937</td>\n",
       "      <td>0.801598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.639762</td>\n",
       "      <td>0.275161</td>\n",
       "      <td>0.419328</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.799773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>0.665469</td>\n",
       "      <td>0.259798</td>\n",
       "      <td>0.430274</td>\n",
       "      <td>0.323979</td>\n",
       "      <td>0.789490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.739562</td>\n",
       "      <td>0.283025</td>\n",
       "      <td>0.431174</td>\n",
       "      <td>0.341734</td>\n",
       "      <td>0.796805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.776141</td>\n",
       "      <td>0.278434</td>\n",
       "      <td>0.429581</td>\n",
       "      <td>0.337874</td>\n",
       "      <td>0.791897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.836094</td>\n",
       "      <td>0.280119</td>\n",
       "      <td>0.436993</td>\n",
       "      <td>0.341397</td>\n",
       "      <td>0.793263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.865031</td>\n",
       "      <td>0.286298</td>\n",
       "      <td>0.431659</td>\n",
       "      <td>0.344264</td>\n",
       "      <td>0.794407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-877\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-877/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-877/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-877/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-877/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-1400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-1754\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-1754/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-1754/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-1754/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-1754/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-1450] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-2631\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-2631/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-2631/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-2631/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-2631/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-877] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-3508\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-3508/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-3508/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-3508/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-3508/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-1754] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-4385\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-4385/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-4385/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-4385/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-4385/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-2631] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-5262\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-5262/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-5262/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-5262/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-5262/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-3508] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-6139\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-6139/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-6139/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-6139/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-6139/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-4385] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-7016\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-7016/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-7016/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-7016/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-7016/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-5262] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-7893\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-7893/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-7893/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-7893/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-7893/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-7016] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/longformer-baseline/checkpoint-8770\n",
      "Configuration saved in ./output/longformer-baseline/checkpoint-8770/config.json\n",
      "Model weights saved in ./output/longformer-baseline/checkpoint-8770/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/longformer-baseline/checkpoint-8770/tokenizer_config.json\n",
      "Special tokens file saved in ./output/longformer-baseline/checkpoint-8770/special_tokens_map.json\n",
      "Deleting older checkpoint [output/longformer-baseline/checkpoint-6139] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./output/longformer-baseline/checkpoint-8770 (score: 0.34426365369209094).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21153... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8492f7dd2044b3c8d4f263371460d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▇▃▆▄▅▅</td></tr><tr><td>eval/f1</td><td>▁▅▇▇▇▇████</td></tr><tr><td>eval/loss</td><td>▃▁▁▁▂▃▅▆▇█</td></tr><tr><td>eval/precision</td><td>▁▅▆▇▇▇████</td></tr><tr><td>eval/recall</td><td>▁▅▇█▇█████</td></tr><tr><td>eval/runtime</td><td>▁▂▃▄▁▃▂█▂▄</td></tr><tr><td>eval/samples_per_second</td><td>█▇▆▅█▆▇▁▇▅</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▆▅█▅▇▁▇▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.79441</td></tr><tr><td>eval/f1</td><td>0.34426</td></tr><tr><td>eval/loss</td><td>0.86503</td></tr><tr><td>eval/precision</td><td>0.2863</td></tr><tr><td>eval/recall</td><td>0.43166</td></tr><tr><td>eval/runtime</td><td>83.789</td></tr><tr><td>eval/samples_per_second</td><td>18.618</td></tr><tr><td>eval/steps_per_second</td><td>2.327</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>8770</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.155</td></tr><tr><td>train/total_flos</td><td>9.168063117487718e+16</td></tr><tr><td>train/train_loss</td><td>0.42746</td></tr><tr><td>train/train_runtime</td><td>19217.9513</td></tr><tr><td>train/train_samples_per_second</td><td>7.303</td></tr><tr><td>train/train_steps_per_second</td><td>0.456</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">longformer-baseline</strong>: <a href=\"https://wandb.ai/donggunseo/Feedback-prize/runs/3o147wzi\" target=\"_blank\">https://wandb.ai/donggunseo/Feedback-prize/runs/3o147wzi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220127_053803-3o147wzi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to best_model/longformer-baseline_best\n",
      "Configuration saved in best_model/longformer-baseline_best/config.json\n",
      "Model weights saved in best_model/longformer-baseline_best/pytorch_model.bin\n",
      "tokenizer config file saved in best_model/longformer-baseline_best/tokenizer_config.json\n",
      "Special tokens file saved in best_model/longformer-baseline_best/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project='Feedback-prize', entity='donggunseo', name='longformer-baseline')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "trainer.train()\n",
    "run.finish()\n",
    "trainer.save_model('best_model/longformer-baseline_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_valid_dataset(examples):\n",
    "    encoding = tokenizer(examples['text_list'], truncation=True, padding=True, max_length = 1024, is_split_into_words=True)\n",
    "    total= len(encoding['input_ids'])\n",
    "    encoding['labels']=[]\n",
    "    encoding['word_ids']=[]\n",
    "    for i in range(total):\n",
    "        labels = [l2i['O'] for _ in range(len(encoding['input_ids'][i]))]\n",
    "        word_idx = encoding.word_ids(batch_index=i)\n",
    "        for j in range(len(word_idx)):\n",
    "            if word_idx[j] is None:\n",
    "                labels[j]=l2i['Special']\n",
    "            else:\n",
    "                label = examples['entities'][i][word_idx[j]]\n",
    "                if label[0]=='B' and j!=0 and word_idx[j-1]==word_idx[j]:\n",
    "                    label_t = label.replace('B', 'I')\n",
    "                    labels[j]=l2i[label_t]\n",
    "                else:\n",
    "                    labels[j]=l2i[label]\n",
    "        labels = fix_beginnings(labels)\n",
    "        encoding['labels'].append(labels)\n",
    "        encoding['word_ids'].append(word_idx)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f8aaa05b044557b4a297940a04d5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets_valid = datasets['test'].map(preparing_valid_dataset, batched=True, batch_size=10000, remove_columns=datasets[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: word_ids.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "prediction,_,_ = trainer.predict(tokenized_datasets_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560, 1024, 15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1560it [23:19,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(prediction, axis=-1)\n",
    "x = []\n",
    "for k,label_pred in tqdm(enumerate(preds)):\n",
    "    token_preds = [i2l[i] for i in label_pred]\n",
    "    y = []\n",
    "    word_ids = tokenized_datasets_valid['word_ids'][k]\n",
    "    previous_word_idx = -1\n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx == None:\n",
    "            continue\n",
    "        elif word_idx != previous_word_idx:\n",
    "            y.append(token_preds[idx])\n",
    "            previous_word_idx = word_idx\n",
    "    x.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_id_list = list(datasets['test']['id'])\n",
    "df = pd.DataFrame()\n",
    "for idx in valid_id_list:\n",
    "    dfx = train.loc[train['id']==idx].reset_index(drop=True)\n",
    "    df = pd.concat([df, dfx], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>1.620742e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>Driverless cars is the way the automotive indu...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>1.620742e+12</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>Almost all the successful driverless cars have...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>1.620742e+12</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>The knowledge of how to design a smart car has...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>178 179 180 181 182 183 184 185 186 187 188 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>1.620742e+12</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>Improvments on technology and cheaper technol...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>206 207 208 209 210 211 212 213 214 215 216 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>1.621526e+12</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>People have long dreamed of driverless cars, a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>248 249 250 251 252 253 254 255 256 257 258 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14462</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>1.622820e+12</td>\n",
       "      <td>398.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>Also, people should be able to make urgent calls</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>75 76 77 78 79 80 81 82 83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14463</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>1.622820e+12</td>\n",
       "      <td>480.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>people shouldnt be able to use their cellphon...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>91 92 93 94 95 96 97 98 99 100 101 102 103 104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>1.622820e+12</td>\n",
       "      <td>576.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>it puts not only the driver in danger but othe...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 4</td>\n",
       "      <td>106 107 108 109 110 111 112 113 114 115 116 117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14465</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>1.622820e+12</td>\n",
       "      <td>638.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>Its also ilegal to be on the phone while your ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 5</td>\n",
       "      <td>118 119 120 121 122 123 124 125 126 127 128 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14466</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>1.622820e+12</td>\n",
       "      <td>744.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>The hands free law is a new law in the united ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14467 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  discourse_id  discourse_start  discourse_end  \\\n",
       "0      DE05DCB75D79  1.620742e+12              0.0          398.0   \n",
       "1      DE05DCB75D79  1.620742e+12            399.0         1039.0   \n",
       "2      DE05DCB75D79  1.620742e+12           1040.0         1177.0   \n",
       "3      DE05DCB75D79  1.620742e+12           1178.0         1435.0   \n",
       "4      DE05DCB75D79  1.621526e+12           1436.0         1800.0   \n",
       "...             ...           ...              ...            ...   \n",
       "14462  CFF21231DFEC  1.622820e+12            398.0          446.0   \n",
       "14463  CFF21231DFEC  1.622820e+12            480.0          569.0   \n",
       "14464  CFF21231DFEC  1.622820e+12            576.0          637.0   \n",
       "14465  CFF21231DFEC  1.622820e+12            638.0          743.0   \n",
       "14466  CFF21231DFEC  1.622820e+12            744.0         1594.0   \n",
       "\n",
       "                                          discourse_text discourse_type  \\\n",
       "0      Driverless cars is the way the automotive indu...           Lead   \n",
       "1      Almost all the successful driverless cars have...       Evidence   \n",
       "2      The knowledge of how to design a smart car has...          Claim   \n",
       "3       Improvments on technology and cheaper technol...       Evidence   \n",
       "4      People have long dreamed of driverless cars, a...       Evidence   \n",
       "...                                                  ...            ...   \n",
       "14462   Also, people should be able to make urgent calls          Claim   \n",
       "14463   people shouldnt be able to use their cellphon...          Claim   \n",
       "14464  it puts not only the driver in danger but othe...          Claim   \n",
       "14465  Its also ilegal to be on the phone while your ...          Claim   \n",
       "14466  The hands free law is a new law in the united ...       Evidence   \n",
       "\n",
       "      discourse_type_num                                   predictionstring  \n",
       "0                 Lead 1  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
       "1             Evidence 1  68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 8...  \n",
       "2                Claim 1  178 179 180 181 182 183 184 185 186 187 188 18...  \n",
       "3             Evidence 2  206 207 208 209 210 211 212 213 214 215 216 21...  \n",
       "4             Evidence 3  248 249 250 251 252 253 254 255 256 257 258 25...  \n",
       "...                  ...                                                ...  \n",
       "14462            Claim 2                         75 76 77 78 79 80 81 82 83  \n",
       "14463            Claim 3     91 92 93 94 95 96 97 98 99 100 101 102 103 104  \n",
       "14464            Claim 4    106 107 108 109 110 111 112 113 114 115 116 117  \n",
       "14465            Claim 5  118 119 120 121 122 123 124 125 126 127 128 12...  \n",
       "14466         Evidence 1  139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "\n",
       "[14467 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = []\n",
    "for i in range(len(df)):\n",
    "    idx = df['id'][i]\n",
    "    idx_list = list(df['id'].unique())\n",
    "    pred = x[idx_list.index(idx)]\n",
    "    j = 0\n",
    "    while j < len(pred):\n",
    "        cls = pred[j]\n",
    "        if cls =='O': \n",
    "            j+=1\n",
    "        else: \n",
    "            cls = cls.replace('B', 'I')\n",
    "        end = j+1\n",
    "        while end < len(pred) and pred[end] == cls:\n",
    "            end +=1\n",
    "        if cls != 'O' and cls != '' and end-j>7:\n",
    "            final_pred.append((idx, cls.replace('I-', ''), ' '.join(map(str, list(range(j, end))))))\n",
    "        j = end\n",
    "        \n",
    "oof = pd.DataFrame(final_pred)\n",
    "oof.columns = ['id', 'class', 'predictionstring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>248 249 250 251 252 253 254 255 256 257 258 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>Position</td>\n",
       "      <td>315 316 317 318 319 320 321 322 323 324 325 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>328 329 330 331 332 333 334 335 336 337 338 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142164</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>118 119 120 121 122 123 124 125 126 127 128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142165</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>129 130 131 132 133 134 135 136 137 138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142166</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142167</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>193 194 195 196 197 198 199 200 201 202 203 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142168</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>208 209 210 211 212 213 214 215 216 217 218 21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                 class  \\\n",
       "0       DE05DCB75D79                  Lead   \n",
       "1       DE05DCB75D79              Evidence   \n",
       "2       DE05DCB75D79              Evidence   \n",
       "3       DE05DCB75D79              Position   \n",
       "4       DE05DCB75D79  Concluding Statement   \n",
       "...              ...                   ...   \n",
       "142164  CFF21231DFEC                 Claim   \n",
       "142165  CFF21231DFEC                 Claim   \n",
       "142166  CFF21231DFEC              Evidence   \n",
       "142167  CFF21231DFEC                 Claim   \n",
       "142168  CFF21231DFEC              Evidence   \n",
       "\n",
       "                                         predictionstring  \n",
       "0             0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \n",
       "1       32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 4...  \n",
       "2       248 249 250 251 252 253 254 255 256 257 258 25...  \n",
       "3       315 316 317 318 319 320 321 322 323 324 325 32...  \n",
       "4       328 329 330 331 332 333 334 335 336 337 338 33...  \n",
       "...                                                   ...  \n",
       "142164        118 119 120 121 122 123 124 125 126 127 128  \n",
       "142165            129 130 131 132 133 134 135 136 137 138  \n",
       "142166  139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "142167  193 194 195 196 197 198 199 200 201 202 203 20...  \n",
       "142168  208 209 210 211 212 213 214 215 216 217 218 21...  \n",
       "\n",
       "[142169 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "def link_evidence(oof):\n",
    "  if not len(oof):\n",
    "    return oof\n",
    "  \n",
    "  def jn(pst, start, end):\n",
    "    return \" \".join([str(x) for x in pst[start:end]])\n",
    "  \n",
    "  thresh = 1\n",
    "  idu = oof['id'].unique()\n",
    "  eoof = oof[oof['class'] == \"Evidence\"]\n",
    "  neoof = oof[oof['class'] != \"Evidence\"]\n",
    "  eoof.index = eoof[['id', 'class']]\n",
    "  for thresh2 in range(26, 27, 1):\n",
    "    retval = []\n",
    "    for idv in tqdm(idu, desc='link_evidence', leave=False):\n",
    "      for c in ['Evidence']:\n",
    "        q = eoof[(eoof['id'] == idv)]\n",
    "        if len(q) == 0:\n",
    "          continue\n",
    "        pst = []\n",
    "        for r in q.itertuples():\n",
    "          pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n",
    "        start = 1\n",
    "        end = 1\n",
    "        for i in range(2, len(pst)):\n",
    "          cur = pst[i]\n",
    "          end = i\n",
    "          if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n",
    "            retval.append((idv, c, jn(pst, start, end)))\n",
    "            start = i + 1\n",
    "        v = (idv, c, jn(pst, start, end + 1))\n",
    "        retval.append(v)\n",
    "    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n",
    "    roof = roof.merge(neoof, how='outer')\n",
    "    return roof\n",
    "\n",
    "oof = link_evidence(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE05DCB75D79</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>248 249 250 251 252 253 254 255 256 257 258 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8C4C7081A2AF</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>160 161 162 163 164 165 166 167 168 169 170 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8C4C7081A2AF</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>219 220 221 222 223 224 225 226 227 228 229 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8C4C7081A2AF</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>219 220 221 222 223 224 225 226 227 228 229 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126523</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>193 194 195 196 197 198 199 200 201 202 203 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126524</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>193 194 195 196 197 198 199 200 201 202 203 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126525</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>193 194 195 196 197 198 199 200 201 202 203 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126526</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>193 194 195 196 197 198 199 200 201 202 203 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126527</th>\n",
       "      <td>CFF21231DFEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>193 194 195 196 197 198 199 200 201 202 203 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126528 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     class  \\\n",
       "0       DE05DCB75D79  Evidence   \n",
       "1       DE05DCB75D79  Evidence   \n",
       "2       8C4C7081A2AF  Evidence   \n",
       "3       8C4C7081A2AF  Evidence   \n",
       "4       8C4C7081A2AF  Evidence   \n",
       "...              ...       ...   \n",
       "126523  CFF21231DFEC     Claim   \n",
       "126524  CFF21231DFEC     Claim   \n",
       "126525  CFF21231DFEC     Claim   \n",
       "126526  CFF21231DFEC     Claim   \n",
       "126527  CFF21231DFEC     Claim   \n",
       "\n",
       "                                         predictionstring  \n",
       "0       32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 4...  \n",
       "1       248 249 250 251 252 253 254 255 256 257 258 25...  \n",
       "2       160 161 162 163 164 165 166 167 168 169 170 17...  \n",
       "3       219 220 221 222 223 224 225 226 227 228 229 23...  \n",
       "4       219 220 221 222 223 224 225 226 227 228 229 23...  \n",
       "...                                                   ...  \n",
       "126523  193 194 195 196 197 198 199 200 201 202 203 20...  \n",
       "126524  193 194 195 196 197 198 199 200 201 202 203 20...  \n",
       "126525  193 194 195 196 197 198 199 200 201 202 203 20...  \n",
       "126526  193 194 195 196 197 198 199 200 201 202 203 20...  \n",
       "126527  193 194 195 196 197 198 199 200 201 202 203 20...  \n",
       "\n",
       "[126528 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.14584103512014787\n",
      "Position 0.12865816222116105\n",
      "Evidence 0.1624319646843412\n",
      "Claim 0.1001296582876741\n",
      "Concluding Statement 0.14270352330950725\n",
      "Counterclaim 0.08195035981788809\n",
      "Rebuttal 0.06278713629402756\n",
      "Overall 0.11778597710496386\n"
     ]
    }
   ],
   "source": [
    "f1s=[]\n",
    "for c in classes:\n",
    "    pred_df = oof.loc[oof['class']==c].copy()\n",
    "    gt_df = df.loc[df['discourse_type']==c].copy()\n",
    "    f1 = score_feedback_comp(pred_df, gt_df)\n",
    "    print(c,f1)\n",
    "    f1s.append(f1)\n",
    "print('Overall', np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8344be4878adc6549e572326e5ceaef6fa6a6636d73e1c07dab1555c32c9e2c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}